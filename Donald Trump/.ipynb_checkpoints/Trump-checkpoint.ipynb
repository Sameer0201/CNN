{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "Sameer Gupta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project I will train an LSTM to complete sentences in Shakespeare. This project could even be generalized to any dataset, so in theory this same model can be trained on different authors, on music lyrics to help people to generate their own text on whatever way they like.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 0: Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found all the entire collection of Shakespeare's text online at Gutenbergs. I sorted through them and found something interesting. Shakespeare's entire collection consists of sonnets, plays and other sort work. But they are all different in their pattern. Plays depend on dialogues and sort change of scenes which were descripted in modern english. \n",
    "\n",
    "I was a bit skeptical on training the whole model on the entire collection but went ahead anyway. It did not work as I expected, so I decided to change my approach and only focus on 14 lines on sonnets which add a much more intuitive repeating pattern than in plays. \n",
    "\n",
    "A sonnet is a fourteen-line poem written in iambic pentameter, which employ one of several rhyme schemes and adhere to a tightly structured thematic organization.\n",
    "\n",
    "The neural net would perform better if it is given patterns which it can recognize and then recreate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras import utils as np_utils\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump = pd.read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/SameerGupta/Desktop/CMSC389A/FinalProject/shakespeare/Sonnets/*.txt'   \n",
    "files = glob.glob(path)\n",
    "Poems = []\n",
    "for name in files: # 'file' is a builtin type, 'name' is a less-ambiguous variable name.\n",
    "    try:\n",
    "        with open(name) as f: # No need to specify 'r': this is the default.\n",
    "            Poems.append(f.read().lower())\n",
    "    except IOError as exc:\n",
    "        if exc.errno != errno.EISDIR: # Do not fail if a directory is found, just ignore it.\n",
    "            raise # Propagate other kinds of IOError."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I import all sonnet files and concat them to each other. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems = \"\"\n",
    "for i in range(len(Poems)):\n",
    "    poems+=str(Poems[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263795"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_length = len(poems)\n",
    "text_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Character Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As machines can understand numbers better than words, we will create an character embedding. This is very simple, we will merely loook at all the unique characters in the string and assign them a number. \n",
    "\n",
    "We will make two lists, one from characters to numbers and the other one from numbers to characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = sorted(list(set(poems)))\n",
    "\n",
    "n_to_char = {n:char for n, char in enumerate(characters)}\n",
    "char_to_n = {char:n for n, char in enumerate(characters)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I left in next line and tab characters, I was very suprised to see the neural net actually pick on them as well, and learn it means next line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\t': 0,\n",
       " '\\n': 1,\n",
       " ' ': 2,\n",
       " '!': 3,\n",
       " \"'\": 4,\n",
       " ',': 5,\n",
       " '-': 6,\n",
       " '.': 7,\n",
       " ':': 8,\n",
       " ';': 9,\n",
       " '?': 10,\n",
       " '[': 11,\n",
       " ']': 12,\n",
       " 'a': 13,\n",
       " 'b': 14,\n",
       " 'c': 15,\n",
       " 'd': 16,\n",
       " 'e': 17,\n",
       " 'f': 18,\n",
       " 'g': 19,\n",
       " 'h': 20,\n",
       " 'i': 21,\n",
       " 'j': 22,\n",
       " 'k': 23,\n",
       " 'l': 24,\n",
       " 'm': 25,\n",
       " 'n': 26,\n",
       " 'o': 27,\n",
       " 'p': 28,\n",
       " 'q': 29,\n",
       " 'r': 30,\n",
       " 's': 31,\n",
       " 't': 32,\n",
       " 'u': 33,\n",
       " 'v': 34,\n",
       " 'w': 35,\n",
       " 'x': 36,\n",
       " 'y': 37,\n",
       " 'z': 38}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will procress through our data to make our training set. We will pick a sequence of 20 characters. Those will be assigned to the training set. The 21st character, the prediction will the corresponding label which will go to the Y train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "sequence_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, text_length-sequence_size):\n",
    "    sequence = poems[i : i + sequence_size]\n",
    "    label =poems[i + sequence_size]\n",
    "    X_train.append([char_to_n[char] for char in sequence])\n",
    "    Y_train.append(char_to_n[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data must be reshaped before it can be used in the training model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_model = np.reshape(X_train, (len(X_train), sequence_size, 1))\n",
    "X_train_model = X_train_model / float(len(characters))\n",
    "Y_train_model = np_utils.to_categorical(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using an LSTM based model. I have three LSTM layers which are split by a Droupout layer which drops the lower values from the LSTM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(800, input_shape=(X_train_model.shape[1], X_train_model.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(800, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(800))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(Y_train_model.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 20, 800)           2566400   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 800)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 20, 800)           5123200   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20, 800)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 800)               5123200   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 39)                31239     \n",
      "=================================================================\n",
      "Total params: 12,844,039\n",
      "Trainable params: 12,844,039\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(X_train_model, Y_train_model, epochs=2, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I trained my model my AWS and now I will load it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights('sonnetMaker.h5', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('/Users/SameerGupta/Desktop/CMSC389A/FinalProject/sonnetMaker.h5', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-Generation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets print our own shakespeare generated text. I will try out multiple cases which are, using versus from his sonnets, some other poems and ordinary texts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(text):\n",
    "    text = str(text)\n",
    "    vector = [char_to_n[char] for char in text[-sequence_size:]]\n",
    "    output = text\n",
    "    \n",
    "    for i in range(200):\n",
    "        input_vector = np.reshape(vector,(1,len(vector), 1))\n",
    "        input_vector = input_vector / float(len(characters))\n",
    "    \n",
    "        pred = np.argmax(model.predict(input_vector, verbose=0))\n",
    "        seq = [n_to_char[value] for value in vector]\n",
    "    \n",
    "        output += n_to_char[pred]\n",
    "    \n",
    "        vector.append(pred)\n",
    "        vector = vector[1:len(vector)]\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapespeare = \"Look in thy glass, and tell the\"\n",
    "shapespeare_2 = \"Then let not winter's ragged hand deface\"\n",
    "whitman = \"A noiseless, patient spider,\"\n",
    "plain_english = \"Hello, My name is Sameer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look in thy glass, and tell the shame of heart that she shall she starsed all the world and she doth begold,\n",
      "and in the world with her shade,\n",
      "where they see the shame of thine,\n",
      "that the world will see the shing that she heart that \n"
     ]
    }
   ],
   "source": [
    "shakespeare_text = generate_text(shapespeare.lower())\n",
    "print(shakespeare_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A noiseless, patient spider, and therefore we admire,\n",
      "and therefore were beauty and the sky,\n",
      "\n",
      "and therefore we lear to the sky,\n",
      "\n",
      "and therefore we lear to the sky,\n",
      "\n",
      "and therefore we lear to the sky,\n",
      "\n",
      "and therefore we lear to the \n"
     ]
    }
   ],
   "source": [
    "whitman_text = generate_text(whitman.lower())\n",
    "print(whitman_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, my name is sameer, and therefore we admire,\n",
      "and therefore were beauty and the sky,\n",
      "\n",
      "and therefore we lear to the sky,\n",
      "\n",
      "and therefore we lear to the sky,\n",
      "\n",
      "and therefore we lear to the sky,\n",
      "\n",
      "and therefore we lear to the \n"
     ]
    }
   ],
   "source": [
    "text = generate_text(plain_english.lower())\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "then let not winter's ragged hand defaced\n",
      "wiere they have seen and the skies that she had not so thee,\n",
      "the strongest sears that she is mott with thee and the despined offence:\n",
      "\n",
      "'then thou art as the sentence of the sight,\n",
      "and she would she \n"
     ]
    }
   ],
   "source": [
    "shakespeare_text = generate_text(shapespeare_2.lower())\n",
    "print(shakespeare_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
